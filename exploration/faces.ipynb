{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faces.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVDLA4IDja74SLzN1sL+ZC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "sc0CcSdnwAw8",
        "outputId": "e1c8361a-8108-467b-b02d-a3baa3032cb0"
      },
      "source": [
        "import dlib\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob \n",
        "\n",
        "def clear_folder():\n",
        "  mydir = \"cropped-faces/\"\n",
        "  filelist = [ f for f in os.listdir(mydir) if f.endswith(\".jpg\") ]\n",
        "  for f in filelist:\n",
        "    os.remove(os.path.join(mydir, f))\n",
        "\n",
        "\n",
        "\n",
        "def detect_faces(image):\n",
        "    face_detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "    detected_faces = face_detector(image, 1)\n",
        "    face_frames = [(x.left(), x.top(),\n",
        "                    x.right(), x.bottom()) for x in detected_faces]\n",
        "    return face_frames\n",
        "\n",
        "df = pd.DataFrame(columns=['filename', 'faces'])\n",
        "all_filename = []\n",
        "all_faces = []\n",
        "\n",
        "for filename in os.listdir(\"faces/\"):\n",
        "  counter = 0\n",
        "  if filename.endswith(\".jpg\"):\n",
        "    img_path = \"faces/\" + filename\n",
        "    image = io.imread(img_path)\n",
        "    detected_faces = detect_faces(image)\n",
        "\n",
        "    all_filename.append(filename)\n",
        "    all_faces.append(len(detected_faces))\n",
        "\n",
        "    for n, face_rect in enumerate(detected_faces):\n",
        "      face = Image.fromarray(image).crop(face_rect)\n",
        "      plt.subplot(1, len(detected_faces), n+1)\n",
        "      plt.axis('off')\n",
        "      new_path = \"cropped-faces/\" + str(counter) + \"-\" + filename \n",
        "      counter += 1;  \n",
        "      plt.savefig(new_path, dpi=300, bbox_inches='tight')\n",
        "\n",
        "df['filename'] = all_filename\n",
        "df['faces'] = all_faces\n",
        "\n",
        "df.to_csv('all-data.csv')\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADKUlEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzAKgcV4HAPzEdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIHQBcjcEy3+fc28AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}